{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statistical-suffering",
   "metadata": {},
   "source": [
    "# 1. Scraping qdrops.online with BeautifulSoup and parsing its content\n",
    "## 1.1 capturing\n",
    "the text we want is contained within this tag hiearcharchy: \n",
    "- div message -> text -> string if not None & p \n",
    "- div message -> div op -> string \n",
    "- div message -> abbr title, abbr.text\n",
    "- meta lar -> span: time, name, source, num\n",
    "\n",
    "### prematurely calling text or get_text() on div_text will render unnecessary text, text we'd later have to clean\n",
    "\n",
    "### tags to extract():\n",
    "- hyperlinks: https?\\S+\\b, www, twitter, instagram, etc (inevitably will have to regex)\n",
    "- a href\n",
    "- figure\n",
    "- figcaption\n",
    "- images\n",
    "- div op containing no text or string\n",
    "- replace punct with a single space, then replace spaces longer than 1 space with a single space\n",
    "- it also might make things easier tokenizing them before hand\n",
    "### cleaning \n",
    "- sub hyperlinks\n",
    "- lower text\n",
    "- split text \n",
    "- sub punctuation\n",
    "- sub digits \n",
    "- join split words back into string\n",
    "- append strings to list if strings \n",
    "- return list of cleaned strings \n",
    "## Recurring Problems\n",
    "### inconsistent tag use: br, p, text, abbr \n",
    "- many more tags could have been abbreviated or propertied with its value\n",
    "- pickling exceeds maximum recursion; solved by sys.get and set a higher recursion limit\n",
    "- runtime of requests is > 1 min: solved by loading the pickled object\n",
    "- unwanted text from hyperlinks, figcaptions, etc; solved by using BeautifulSoup extract() on unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import os, sys\n",
    "import itertools\n",
    "import re, string\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import timeit\n",
    "\n",
    "from string import punctuation, digits\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from string import punctuation, digits\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import RegexpParser, Tree\n",
    "from nltk.util import ngrams\n",
    "\n",
    "punctuation += str('’‘–…“”')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/kylereaves/Documents/GitHub/parsing_madness'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "source": [
    "We don't have to execute the following cell, we can skip to opening the pickled object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"%%time\\nbase_url = 'https://qposts.online/page/' \\nurls = [base_url+str(i) for i in range(1, 105)]\\npage_requests = [requests.get(url) for url in urls]\\nsoups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\\nmessages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\\nmessages_flat = list(itertools.chain.from_iterable(messages))\\nmeta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "'''%%time\n",
    "base_url = 'https://qposts.online/page/' \n",
    "urls = [base_url+str(i) for i in range(1, 105)]\n",
    "page_requests = [requests.get(url) for url in urls]\n",
    "soups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\n",
    "messages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\n",
    "messages_flat = list(itertools.chain.from_iterable(messages))\n",
    "meta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12.2 s, sys: 400 ms, total: 12.6 s\nWall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "with open('messages_flat.pkl', 'rb') as f:\n",
    "    messages = pickle.load(f)\n",
    "with open('meta_flat.pkl', 'rb') as f:\n",
    "    meta_lar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 1.88 ms, sys: 1.08 ms, total: 2.96 ms\nWall time: 2.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('names_joined.pkl', 'rb') as f:\n",
    "    names = pickle.load(f)\n",
    "with open('sources_joined.pkl', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(integer: int):\n",
    "        msg_list = []\n",
    "        for item in messages[integer]:\n",
    "            \n",
    "            if isinstance(item, NavigableString) and item.name is None:\n",
    "                msg_list.append(item.lower())\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'p':\n",
    "                msg_list.append(item.string)\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'div' and item.has_attr('class'):\n",
    "                contents = item.contents\n",
    "                for content in contents:\n",
    "                    if content.name == 'p':\n",
    "                        msg_list.append(content.string)\n",
    "                    if content.name == 'div':\n",
    "                        msg_list.append(content.text)\n",
    "                    if content.name == 'abbr':\n",
    "                        msg_list.append(content.text)\n",
    "                    if isinstance(content, NavigableString):\n",
    "                        msg_list.append(content.lower())\n",
    "            \n",
    "            for div_images in messages[integer].findAll('div', class_='images'):\n",
    "                div_images.extract()\n",
    "            for a_ref in messages[integer].findAll('a', class_='ref'):\n",
    "                a_ref.extract()\n",
    "            for a_href in messages[integer].findAll('a', class_='href'):\n",
    "                a_ref.extract()\n",
    "            for empty_line in messages[integer].findAll('p', class_='body-line empty'):\n",
    "                empty_line.extract()\n",
    "            for br_tag in messages[integer].findAll('br'):\n",
    "                br_tag.replace_with(' ')\n",
    "\n",
    "        cleaned = [item for item in msg_list if item !=\n",
    "                   ' ' and item is not None]\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def dataframe(integer: int):\n",
    "        bs_df = pd.DataFrame({'type': [type(i) for i in messages[integer].div.children],\n",
    "                              'name': [i.name for i in messages[integer].div.children],\n",
    "                              'content': [i for i in messages[integer].div.children]})\n",
    "        return bs_df\n",
    "    \n",
    "    def sents(integer: int):\n",
    "        return nltk.sent_tokenize(' '.join(Messages.get(integer)))\n",
    "\n",
    "    def joined(integer: int):\n",
    "        return ' '.join(Messages.get(integer))\n",
    "\n",
    "    def split(integer: int):\n",
    "        return Messages.joined(integer).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spans:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def nums():\n",
    "        nums = [meta_lar[i].find('span', 'num').get_text() for i in range(0, len(meta_lar))]\n",
    "        return nums\n",
    "                \n",
    "    def sources():\n",
    "        sources = [meta_lar[i].find('span', 'source').get_text() for i in range(0, len(meta_lar))]\n",
    "        links = [meta_lar[i].find('span', 'source').contents[-1].get('href') for i in range(0, len(meta_lar))]\n",
    "        return sources\n",
    "    \n",
    "    def names():\n",
    "        names = [meta_lar[i].find('span', 'name').get_text() for i in range(0, len(meta_lar))]\n",
    "        return names\n",
    "                      \n",
    "    def dates():\n",
    "        date_list = [meta_lar[i].find('span', 'time').get_text()for i in range(0, len(meta_lar))]\n",
    "        dt_idx = pd.to_datetime(date_list, origin='unix', unit='s')\n",
    "        return dt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    'r v d': 'republicans vs democrats',\n",
    "    'rs': 'republicans',\n",
    "    \"r's\": 'republicans',\n",
    "    \"d's\": 'democrats',\n",
    "    'ds': 'democrats',\n",
    "    '[D]': 'Democratic',\n",
    "    ' w ': 'with',\n",
    "    'w/' : 'with',\n",
    "    '&' : 'and',\n",
    "    'president of the united states': 'potus',\n",
    "    'federal bureau of investigation': 'fbi',\n",
    "    'MS-13': 'ms-thirteen',\n",
    "    'COVID19': 'covid',\n",
    "    \"M's\": 'marshalls'\n",
    "}"
   ]
  },
  {
   "source": [
    "### using string with p tags saves us subing hyperlinks\n",
    "### add a conditional statement on the end to pop None from list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://twitter.com/BrentScher/status/1322015793593360384',\n",
       " 'Fact checkers created in effort to reinforce propaganda [digestion]?',\n",
       " 'The battle to prevent truth from reaching the people.',\n",
       " 'The battle to maintain and push division.',\n",
       " 'Divided you are weak.',\n",
       " 'Divided you fight each other.',\n",
       " 'Divided you pose no threat.',\n",
       " 'System of control.',\n",
       " 'Information warfare.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "[i.text for i in messages[10].div.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Fact checkers created in effort to reinforce propaganda [digestion]?',\n",
       " 'The battle to prevent truth from reaching the people.',\n",
       " 'The battle to maintain and push division.',\n",
       " 'Divided you are weak.',\n",
       " 'Divided you fight each other.',\n",
       " 'Divided you pose no threat.',\n",
       " 'System of control.',\n",
       " 'Information warfare.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "[i.string for i in messages[10].div.children if i.string is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['strong', None]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "[i.name for i in meta_lar[1].find('span', 'name').children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('span', {'class': ['num']}),\n",
       " ('span', {'class': ['time']}),\n",
       " ('span', {'class': ['name']}),\n",
       " ('span', {'class': ['source']}),\n",
       " ('span', {'class': ['copy']})]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "[(i.name, i.attrs) for i in meta_lar[0].children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "#drop entire row if name == br?\n",
    "type(Messages.dataframe(4950))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Open your eyes.',\n",
       " 'It finally came out that Rod/Bob were key players in the Uranium scandal. ',\n",
       " 'Don’t you think ',\n",
       " <abbr title=\"President of the United States\">POTUS</abbr>,\n",
       " ' would be tweeting about removal given clear conflict. ',\n",
       " 'Why did ',\n",
       " <abbr title=\"President of the United States\">POTUS</abbr>,\n",
       " ' meet Bob under the cover of ',\n",
       " <abbr title=\"Federal Bureau of Investigation\">FBI</abbr>,\n",
       " ' Dir interview?',\n",
       " 'Bob is unable to serve as Dir per the law.',\n",
       " 'Gowdy comments on Comey (history will ....)',\n",
       " <abbr title=\"President of the United States\">POTUS</abbr>,\n",
       " ' has everything.',\n",
       " 'Not everyone is corrupt (fewer than you think).',\n",
       " 'Follow Huma.',\n",
       " 'Operation Mockingbird.',\n",
       " 'Priority to clean out the bad actors to unite people behind the America First agenda.',\n",
       " 'Many in our govt worship Satan.',\n",
       " 'Not about Republicans v Democrats at this stage.',\n",
       " 'Where is ',\n",
       " <abbr title=\"Hillary Rodham Clinton\">HRC</abbr>,\n",
       " '?',\n",
       " 'Why is the ',\n",
       " <abbr title=\"National Guard\">NG</abbr>,\n",
       " ' called up across 12 cities?',\n",
       " 'Trust in your President.',\n",
       " 'God bless, Patriots.']"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "Messages.dataframe(4950).drop(Messages.dataframe(4950)[Messages.dataframe(4950).name == 'br'].index)['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['for the coming days ahead.',\n",
       " 'ask yourself an honest question, why would a billionaire who has it all, fame, fortune, a warm and loving family, friends, etc.',\n",
       " 'want to endanger himself and his family by becoming  POTUS ?',\n",
       " 'why would he want to target himself and those he cares about?',\n",
       " 'does he need money?',\n",
       " 'does he need fame?',\n",
       " 'what does he get out of this?',\n",
       " 'does he want to make the us/world a better place for his family and for those good and decent people who have long been taken advantage of?',\n",
       " 'perhaps he could not stomach the thought of mass murders occurring to satisfy moloch?',\n",
       " 'perhaps he could not stomach the thought of children being kidnapped, drugged, and raped while leaders/law enforcement of the world turn a blind eye.',\n",
       " 'perhaps he was tired of seeing how certain races/countries were being constantly abused and kept in need/poor/and suffering all for a specific purpose.',\n",
       " 'perhaps he could not in good conscious see the world burn.',\n",
       " 'why, hours after the election, did seven people travel to an undisclosed location to hold a very private & highly secured/guarded meeting?',\n",
       " 'why didn’t  HRC  give a concession speech?',\n",
       " 'when was the last time a presidential candidate didn’t personally give a concession speech?',\n",
       " 'what happens if the border remained open and the  MSM  continued to brainwash?',\n",
       " 'at what point do patriots, and hard working men and woman, become the minority?',\n",
       " 'what about voting machines?',\n",
       " 'who owns the voting machines?',\n",
       " 'what about voter  ID  laws?',\n",
       " 'photo  ID ?',\n",
       " 'when is it necessary and must be presented?',\n",
       " 'make a list.',\n",
       " 'laugh.',\n",
       " 'reconcile.',\n",
       " 'would the chances of defeating evil grow less and less with each passing year?',\n",
       " 'what does ‘red line’ mean?',\n",
       " 'why, again, were the arrests made in  SA  so very important?',\n",
       " 'what strings were immediately cut?',\n",
       " 'follow the money.',\n",
       " 'when does a bird sing?',\n",
       " 'q']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "Messages.sents(4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nums_s = pd.Series(Spans.nums())\n",
    "#dates_s = pd.Series(Spans.dates())\n",
    "#names_s = pd.Series(Spans.names())\n",
    "#sources_s = pd.Series(Spans.sources())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(data=[nums_s, dates_s, names_s, sources_s]).T\n",
    "#df[1] = pd.to_datetime(df[1], origin='unix', unit='ns')\n",
    "#df.rename(columns={0: 'number', 1: 'datetime', 2: 'name', 3: 'source' }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_pickle('index_df.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}