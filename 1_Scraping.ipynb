{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statistical-suffering",
   "metadata": {},
   "source": [
    "# 1. Scraping qdrops.online with BeautifulSoup and parsing its content\n",
    "## 1.1 capturing\n",
    "the text we want is contained within this tag hiearcharchy: \n",
    "- div message -> text -> string if not None & p \n",
    "- div message -> div op -> string \n",
    "- div message -> abbr title, abbr.text\n",
    "- meta lar -> span: time, name, source, num\n",
    "\n",
    "### prematurely calling text or get_text() on div_text will render unnecessary text, text we'd later have to clean\n",
    "\n",
    "### tags to extract():\n",
    "- hyperlinks: https?\\S+\\b, www, twitter, instagram, etc (inevitably will have to regex)\n",
    "- a href\n",
    "- figure\n",
    "- figcaption\n",
    "- images\n",
    "- div op containing no text or string\n",
    "- replace punct with a single space, then replace spaces longer than 1 space with a single space\n",
    "- it also might make things easier tokenizing them before hand\n",
    "### cleaning \n",
    "- sub hyperlinks\n",
    "- lower text\n",
    "- split text \n",
    "- sub punctuation\n",
    "- sub digits \n",
    "- join split words back into string\n",
    "- append strings to list if strings \n",
    "- return list of cleaned strings \n",
    "## Recurring Problems\n",
    "### inconsistent tag use: br, p, text, abbr \n",
    "- many more tags could have been abbreviated or propertied with its value\n",
    "- pickling exceeds maximum recursion; solved by sys.get and set a higher recursion limit\n",
    "- runtime of requests is > 1 min: solved by loading the pickled object\n",
    "- unwanted text from hyperlinks, figcaptions, etc; solved by using BeautifulSoup extract() on unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import os, sys\n",
    "import itertools\n",
    "import re, string\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import timeit\n",
    "\n",
    "from string import punctuation, digits\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from string import punctuation, digits\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import RegexpParser, Tree\n",
    "from nltk.util import ngrams\n",
    "\n",
    "punctuation += str('’‘–…“”')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "source": [
    "We don't have to execute the following cell, we can skip to opening the pickled object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"%%time\\nbase_url = 'https://qposts.online/page/' \\nurls = [base_url+str(i) for i in range(1, 105)]\\npage_requests = [requests.get(url) for url in urls]\\nsoups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\\nmessages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\\nmessages_flat = list(itertools.chain.from_iterable(messages))\\nmeta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "'''%%time\n",
    "base_url = 'https://qposts.online/page/' \n",
    "urls = [base_url+str(i) for i in range(1, 105)]\n",
    "page_requests = [requests.get(url) for url in urls]\n",
    "soups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\n",
    "messages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\n",
    "messages_flat = list(itertools.chain.from_iterable(messages))\n",
    "meta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/kylereaves/Documents/GitHub/parsing_madness'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_pickle('index_df.pkl')\n",
    "index_df.number = index_df.number.astype('int')\n",
    "date = [index_df.datetime[i].date() for i in range(0, len(index_df.datetime))]\n",
    "time = [index_df.datetime[i].time() for i in range(0, len(index_df.datetime))]\n",
    "dt_index = pd.MultiIndex.from_arrays([date, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12.8 s, sys: 477 ms, total: 13.2 s\nWall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "with open('messages_flat.pkl', 'rb') as f:\n",
    "    messages = pickle.load(f)\n",
    "with open('meta_flat.pkl', 'rb') as f:\n",
    "    meta_lar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2.02 ms, sys: 1.43 ms, total: 3.45 ms\nWall time: 8.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('names_joined.pkl', 'rb') as f:\n",
    "    names = pickle.load(f)\n",
    "with open('sources_joined.pkl', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(integer: int):\n",
    "        msg_list = []\n",
    "        for item in messages[integer]:\n",
    "            \n",
    "            if isinstance(item, NavigableString) and item.name is None:\n",
    "                msg_list.append(item)\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'p':\n",
    "                msg_list.append(item.string)\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'div' and item.has_attr('class'):\n",
    "                contents = item.contents\n",
    "                for content in contents:\n",
    "                    if content.name == 'p':\n",
    "                        msg_list.append(content.string)\n",
    "                    if content.name == 'div':\n",
    "                        msg_list.append(content.text)\n",
    "                    if content.name == 'abbr':\n",
    "                        msg_list.append(content.text)\n",
    "                    if isinstance(content, NavigableString):\n",
    "                        msg_list.append(content)\n",
    "            \n",
    "            for div_images in messages[integer].findAll('div', class_='images'):\n",
    "                div_images.extract()\n",
    "            for a_ref in messages[integer].findAll('a', class_='ref'):\n",
    "                a_ref.extract()\n",
    "            for a_href in messages[integer].findAll('a', class_='href'):\n",
    "                a_ref.extract()\n",
    "            for empty_line in messages[integer].findAll('p', class_='body-line empty'):\n",
    "                empty_line.extract()\n",
    "            for br_tag in messages[integer].findAll('br'):\n",
    "                br_tag.replace_with(' ')\n",
    "\n",
    "        cleaned = [item for item in msg_list if item !=\n",
    "                   ' ' and item is not None]\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def dataframe(integer: int):\n",
    "        df = pd.DataFrame({'type': [type(i) for i in messages[integer].div.children],\n",
    "                           'name': [i.name for i in messages[integer].div.children],\n",
    "                           'content': [i for i in messages[integer].div.children]})\n",
    "        return df\n",
    "    \n",
    "    def get_abbr(integer:int): \n",
    "        return Messages.dataframe(integer)[Messages.dataframe(integer).name == 'abbr']\n",
    "    \n",
    "    def sents(integer: int):\n",
    "        return nltk.sent_tokenize(' '.join(Messages.get(integer)))\n",
    "\n",
    "    def joined(integer: int):\n",
    "        return ' '.join(Messages.get(integer))\n",
    "\n",
    "    def split(integer: int):\n",
    "        return Messages.joined(integer).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spans:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def nums():\n",
    "        nums = [meta_lar[i].find('span', 'num').get_text() for i in range(0, len(meta_lar))]\n",
    "        return nums\n",
    "                \n",
    "    def sources():\n",
    "        sources = [meta_lar[i].find('span', 'source').get_text() for i in range(0, len(meta_lar))]\n",
    "        links = [meta_lar[i].find('span', 'source').contents[-1].get('href') for i in range(0, len(meta_lar))]\n",
    "        return sources\n",
    "    \n",
    "    def names():\n",
    "        names = [meta_lar[i].find('span', 'name').get_text() for i in range(0, len(meta_lar))]\n",
    "        return names\n",
    "                      \n",
    "    def dates():\n",
    "        date_list = [meta_lar[i].find('span', 'time').get_text()for i in range(0, len(meta_lar))]\n",
    "        dt_idx = pd.to_datetime(date_list, origin='unix', unit='s')\n",
    "        return dt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an item in Messages.split(i) is in replace_dict.keys(), replace i (the key) with its value\n",
    "replace_dict = {\n",
    "    'r v d': 'republicans vs democrats',\n",
    "    'rs': 'republicans',\n",
    "    \"r's\": 'republicans',\n",
    "    \"d's\": 'democrats',\n",
    "    'ds': 'democrats',\n",
    "    '[D]': 'Democratic',\n",
    "    'US': 'United States',\n",
    "    ' w ': 'with',\n",
    "    'w/' : 'with',\n",
    "    '&' : 'and',\n",
    "    'MSM': 'mainstream media',\n",
    "    'ID': 'identification',\n",
    "    'SA': 'Saudi Arabia',    \n",
    "    'MS-13': 'ms thirteen',\n",
    "    'COVID19': 'covid',\n",
    "    \"M's\": 'marshalls'\n",
    "}"
   ]
  },
  {
   "source": [
    "### using string with p tags saves us subing hyperlinks\n",
    "### add a conditional statement on the end to pop None from list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://twitter.com/BrentScher/status/1322015793593360384',\n",
       " 'Fact checkers created in effort to reinforce propaganda [digestion]?',\n",
       " 'The battle to prevent truth from reaching the people.',\n",
       " 'The battle to maintain and push division.',\n",
       " 'Divided you are weak.',\n",
       " 'Divided you fight each other.',\n",
       " 'Divided you pose no threat.',\n",
       " 'System of control.',\n",
       " 'Information warfare.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "[i.text for i in messages[10].div.children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Fact checkers created in effort to reinforce propaganda [digestion]?',\n",
       " 'The battle to prevent truth from reaching the people.',\n",
       " 'The battle to maintain and push division.',\n",
       " 'Divided you are weak.',\n",
       " 'Divided you fight each other.',\n",
       " 'Divided you pose no threat.',\n",
       " 'System of control.',\n",
       " 'Information warfare.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "[i.string for i in messages[10].div.children if i.string is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['strong', None]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "[i.name for i in meta_lar[1].find('span', 'name').children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('span', {'class': ['num']}),\n",
       " ('span', {'class': ['time']}),\n",
       " ('span', {'class': ['name']}),\n",
       " ('span', {'class': ['source']}),\n",
       " ('span', {'class': ['copy']})]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "[(i.name, i.attrs) for i in meta_lar[0].children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#drop entire row if name == br?\n",
    "type(Messages.dataframe(4950))"
   ]
  },
  {
   "source": [
    "Now that we have the index taken care of, we can now focus on how to replace\n",
    "\n",
    "abbr keys with their values in the the dictionary we've been adding too\n",
    "\n",
    "Remember the are abbrs we want to skip as an exception: POTUS, FBI, HRC, abbrs\n",
    "\n",
    "whose meaning is obvious and likely won't cloud our analysis of the language "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ".index() returns the index of the values first appearance in a list, not all of the indices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "& 182\nMSM 216\nID 246\nID 246\nSA 290\n"
     ]
    }
   ],
   "source": [
    "for item in Messages.split(4800):\n",
    "    if item in replace_dict.keys():\n",
    "        print(item, Messages.split(4800).index(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [i for i,e in enumerate(Messages.split(4800)) if e in replace_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['&']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "[e for i,e in enumerate(Messages.split(4800)) if i == 182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['&', 'ID', 'ID']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "[e for i,e in enumerate(Messages.split(4800)) if i in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "replace_dict.get('&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How\nbad\nis\nthe\ncorruption?\nFBI\n(past/present)\n#1\n#1\n#2\n+29\n(16)\nDOJ\n(past/present)\n#1\n#1\n#2\n+18\nSTATE\n(past/present)\n#1\n#1\n+41\nRemoval\nis\nthe\nleast\nof\ntheir\nproblems.\nProjection.\nRussia>D/\nHRC\nTwitter\nBots>\nGOOG\noperated\n(not\nRussia)/Narrative\nand\nPolitical\nSLANT\nBIDEN\n/\nCHINA.\nBIG\nDEVELOPMENT.\nTRAITORS\nEVERYWHERE.\nAMERICA\nFOR\nSALE.\nFLYNN.\nTargeted.\nWhy?\nWho\nknows\nwhere\nthe\nbodies\nare\nburied?\nCLEARED\nOF\nALL\nCHARGES.\nTRUMP\nADMIN\nv2?\nElection\ntheft.\nLast\nhope.\nCongressional\nfocus.\nImpeach.\nThey\nthink\nyou\nare\nSTUPID.\nThey\nthink\nyou\nwill\nfollow\nthe\nSTARS.\nThey\nopenly\ncall\nyou\nSHEEP/CATTLE.\nTHERE\nWILL\nCOME\nA\nTIME\nNONE\nOF\nTHEM\nWILL\nBE\nABLE\nTO\nWALK\nDOWN\nTHE\nSTREET.\nBIGGEST\nFEAR.\nPUBLIC\nAWAKENING.\nQ\n"
     ]
    }
   ],
   "source": [
    "for item in Messages.split(4000):\n",
    "    if item in replace_dict.keys():\n",
    "        item =  replace_dict.get(item)\n",
    "        print(item)\n",
    "    else:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         type  name  content\n",
       "3   <class 'bs4.element.Tag'>  abbr  [POTUS]\n",
       "27  <class 'bs4.element.Tag'>  abbr    [HRC]\n",
       "33  <class 'bs4.element.Tag'>  abbr    [MSM]\n",
       "43  <class 'bs4.element.Tag'>  abbr     [ID]\n",
       "47  <class 'bs4.element.Tag'>  abbr     [ID]\n",
       "57  <class 'bs4.element.Tag'>  abbr     [SA]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>name</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[POTUS]</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[HRC]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[MSM]</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[ID]</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[ID]</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>abbr</td>\n      <td>[SA]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "Messages.get_abbr(4800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['How bad is the corruption?',\n",
       " 'FBI  (past/present) #1 #1  #2 +29 (16) DOJ  (past/present) #1 #1 #2  +18  STATE (past/present) #1 #1 +41 Removal is the least of their problems.',\n",
       " 'Projection.',\n",
       " 'Russia>D/ HRC Twitter Bots> GOOG  operated (not Russia)/Narrative & Political SLANT BIDEN / CHINA.',\n",
       " 'BIG DEVELOPMENT.',\n",
       " 'TRAITORS EVERYWHERE.',\n",
       " 'AMERICA FOR SALE.',\n",
       " 'FLYNN.',\n",
       " 'Targeted.',\n",
       " 'Why?',\n",
       " 'Who knows where the bodies are buried?',\n",
       " 'CLEARED OF ALL CHARGES.',\n",
       " 'TRUMP ADMIN v2?',\n",
       " 'Election theft.',\n",
       " 'Last hope.',\n",
       " 'Congressional focus.',\n",
       " 'Impeach.',\n",
       " 'They think you are STUPID.',\n",
       " 'They think you will follow the STARS.',\n",
       " 'They openly call you SHEEP/CATTLE.',\n",
       " 'THERE WILL COME A TIME NONE OF THEM WILL BE ABLE TO WALK DOWN THE STREET.',\n",
       " 'BIGGEST FEAR.',\n",
       " 'PUBLIC AWAKENING.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "Messages.sents(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     number            datetime            name                 source\n",
       "953    4000 2020-04-29 00:58:18  Q !!Hs1Jq13jV6  8kun/qresearch8953725"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>datetime</th>\n      <th>name</th>\n      <th>source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>953</th>\n      <td>4000</td>\n      <td>2020-04-29 00:58:18</td>\n      <td>Q !!Hs1Jq13jV6</td>\n      <td>8kun/qresearch8953725</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "index_df[index_df.number == 4000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}