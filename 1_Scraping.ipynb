{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "statistical-suffering",
   "metadata": {},
   "source": [
    "# 1. Scraping qdrops.online with BeautifulSoup and parsing its content\n",
    "## 1.1 capturing\n",
    "the text we want is contained within this tag hiearcharchy: \n",
    "- div message -> text -> string if not None & p \n",
    "- div message -> div op -> string \n",
    "- div message -> abbr title, abbr.text\n",
    "- meta lar -> span: time, name, source, num\n",
    "\n",
    "### prematurely calling text or get_text() on div_text will render unnecessary text, text we'd later have to clean\n",
    "\n",
    "### tags to extract():\n",
    "- hyperlinks: https?\\S+\\b, www, twitter, instagram, etc (inevitably will have to regex)\n",
    "- a href\n",
    "- figure\n",
    "- figcaption\n",
    "- images\n",
    "- div op containing no text or string\n",
    "- replace punct with a single space, then replace spaces longer than 1 space with a single space\n",
    "- it also might make things easier tokenizing them before hand\n",
    "### cleaning \n",
    "- sub hyperlinks\n",
    "- lower text\n",
    "- split text \n",
    "- sub punctuation\n",
    "- sub digits \n",
    "- join split words back into string\n",
    "- append strings to list if strings \n",
    "- return list of cleaned strings \n",
    "## Recurring Problems\n",
    "### inconsistent tag use: br, p, text, abbr \n",
    "- many more tags could have been abbreviated or propertied with its value\n",
    "- pickling exceeds maximum recursion; solved by sys.get and set a higher recursion limit\n",
    "- runtime of requests is > 1 min: solved by loading the pickled object\n",
    "- unwanted text from hyperlinks, figcaptions, etc; solved by using BeautifulSoup extract() on unwanted objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import os, sys\n",
    "import itertools\n",
    "import re, string\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import timeit\n",
    "\n",
    "from string import punctuation, digits\n",
    "from collections import Counter\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "from string import punctuation, digits\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk import RegexpParser, Tree\n",
    "from nltk.util import ngrams\n",
    "\n",
    "punctuation += str('’‘–…“”')\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "source": [
    "We don't have to execute the following cell, we can skip to opening the pickled object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"%%time\\nbase_url = 'https://qposts.online/page/' \\nurls = [base_url+str(i) for i in range(1, 105)]\\npage_requests = [requests.get(url) for url in urls]\\nsoups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\\nmessages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\\nmessages_flat = list(itertools.chain.from_iterable(messages))\\nmeta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]\""
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "'''%%time\n",
    "base_url = 'https://qposts.online/page/' \n",
    "urls = [base_url+str(i) for i in range(1, 105)]\n",
    "page_requests = [requests.get(url) for url in urls]\n",
    "soups = [BeautifulSoup(page.text, 'html.parser') for page in page_requests]\n",
    "messages_original = [soups[i].findAll('div', 'message') for i in range(0, len(soups))]\n",
    "messages_flat = list(itertools.chain.from_iterable(messages))\n",
    "meta_lar = [soups[i].findAll('div', 'meta lar') for i in range(0, len(soups))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'/Users/kylereaves/Documents/GitHub/parsing_madness'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_df = pd.read_pickle('index_df.pkl')\n",
    "index_df.number = index_df.number.astype('int')\n",
    "date = [index_df.datetime[i].date() for i in range(0, len(index_df.datetime))]\n",
    "time = [index_df.datetime[i].time() for i in range(0, len(index_df.datetime))]\n",
    "dt_index = pd.MultiIndex.from_arrays([date, time])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12.3 s, sys: 398 ms, total: 12.7 s\nWall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "with open('messages_flat.pkl', 'rb') as f:\n",
    "    messages = pickle.load(f)\n",
    "with open('meta_flat.pkl', 'rb') as f:\n",
    "    meta_lar = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 2.05 ms, sys: 1.24 ms, total: 3.29 ms\nWall time: 2.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open('names_joined.pkl', 'rb') as f:\n",
    "    names = pickle.load(f)\n",
    "with open('sources_joined.pkl', 'rb') as f:\n",
    "    sources = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Messages(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(integer: int):\n",
    "        msg_list = []\n",
    "\n",
    "        for item in messages[integer]:\n",
    "            \n",
    "            if isinstance(item, NavigableString) and item.name is None:\n",
    "                msg_list.append(item)\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'p':\n",
    "                msg_list.append(item.string)\n",
    "            \n",
    "            if isinstance(item, Tag) and item.name == 'div' and item.attrs == {'class': ['text']}:\n",
    "                msg_list.append(item.text)\n",
    "                '''contents = item.contents\n",
    "                for content in contents:\n",
    "                    if content.name == 'p':\n",
    "                        msg_list.append(content.string)\n",
    "                    if content.name == 'em':\n",
    "                        msg_list.append(content.text.strip())\n",
    "                    if content.name == 'div':\n",
    "                        msg_list.append(content.text)\n",
    "                    if content.name == 'abbr':\n",
    "                        msg_list.append(content.text)\n",
    "                    if isinstance(content, NavigableString):\n",
    "                        msg_list.append(content)'''\n",
    "            \n",
    "            for div_images in messages[integer].findAll('div', class_='images'):\n",
    "                div_images.extract()\n",
    "            for a_ref in messages[integer].findAll('a', class_='ref'):\n",
    "                a_ref.extract()\n",
    "            for a_href in messages[integer].findAll('a', class_='href'):\n",
    "                a_ref.extract()\n",
    "            for empty_line in messages[integer].findAll('p', class_='body-line empty'):\n",
    "                empty_line.extract()\n",
    "            for br_tag in messages[integer].findAll('br'):\n",
    "                br_tag.replace_with(' ')\n",
    "\n",
    "        cleaned = [item for item in msg_list if item !=\n",
    "                   ' ' and item is not None]\n",
    "\n",
    "        return cleaned\n",
    "\n",
    "    def dataframe(integer: int):\n",
    "        df = pd.DataFrame({'type': [type(i) for i in messages[integer].div.children],\n",
    "                           'name': [i.name for i in messages[integer].div.children],\n",
    "                           'content': [i for i in messages[integer].div.children]})\n",
    "        return df\n",
    "    \n",
    "    def get_abbr(integer:int): \n",
    "        return Messages.dataframe(integer)[Messages.dataframe(integer).name == 'abbr']\n",
    "\n",
    "    def info(integer:int):\n",
    "        return index_df[index_df.number == integer]\n",
    "    \n",
    "    def sents(integer: int):\n",
    "        return nltk.sent_tokenize(' '.join(Messages.get(integer)))\n",
    "\n",
    "    def joined(integer: int):\n",
    "        return ' '.join(Messages.get(integer))\n",
    "\n",
    "    def split(integer: int):\n",
    "        return Messages.joined(integer).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spans:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def nums():\n",
    "        nums = [meta_lar[i].find('span', 'num').get_text() for i in range(0, len(meta_lar))]\n",
    "        return nums\n",
    "                \n",
    "    def sources():\n",
    "        sources = [meta_lar[i].find('span', 'source').get_text() for i in range(0, len(meta_lar))]\n",
    "        links = [meta_lar[i].find('span', 'source').contents[-1].get('href') for i in range(0, len(meta_lar))]\n",
    "        return sources\n",
    "    \n",
    "    def names():\n",
    "        names = [meta_lar[i].find('span', 'name').get_text() for i in range(0, len(meta_lar))]\n",
    "        return names\n",
    "                      \n",
    "    def dates():\n",
    "        date_list = [meta_lar[i].find('span', 'time').get_text()for i in range(0, len(meta_lar))]\n",
    "        dt_idx = pd.to_datetime(date_list, origin='unix', unit='s')\n",
    "        return dt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if an item in Messages.split(i) is in replace_dict.keys(), replace i (the key) with its value\n",
    "replace_dict = {'r v d': 'republicans vs democrats',\n",
    " 'rs': 'republicans',\n",
    " \"r's\": 'republicans',\n",
    " \"d's\": 'democrats',\n",
    " 'ds': 'democrats',\n",
    " '[D]': 'Democratic',\n",
    " 'US': 'United States',\n",
    " ' w ': 'with',\n",
    " 'w/': 'with',\n",
    " '&': 'and',\n",
    " 'MSM': 'mainstream media',\n",
    " 'ID': 'identification',\n",
    " 'SA': 'Saudi Arabia',\n",
    " 'MS-13': 'ms thirteen',\n",
    " 'COVID19': 'covid',\n",
    " \"M's\": 'marshalls',\n",
    " 'HUSSEIN': 'Barack Obama',\n",
    " 'BRENNAN': 'John Brennan',\n",
    " 'MERKEL': 'Angela Merkel',\n",
    " 'KERRY': 'John Kerry',\n",
    " 'v2': 'version two',\n",
    " 'U.S.': 'United States',\n",
    " \"Gov't\": 'government'}"
   ]
  },
  {
   "source": [
    "### using string with p tags saves us subing hyperlinks\n",
    "### add a conditional statement on the end to pop None from list"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Fact checkers created in effort to reinforce propaganda [digestion]?',\n",
       " 'The battle to prevent truth from reaching the people.',\n",
       " 'The battle to maintain and push division.',\n",
       " 'Divided you are weak.',\n",
       " 'Divided you fight each other.',\n",
       " 'Divided you pose no threat.',\n",
       " 'System of control.',\n",
       " 'Information warfare.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "[i.string for i in messages[10].div if i.string is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                        type name  \\\n",
       "0  <class 'bs4.element.Tag'>    p   \n",
       "1  <class 'bs4.element.Tag'>    p   \n",
       "2  <class 'bs4.element.Tag'>    p   \n",
       "3  <class 'bs4.element.Tag'>    p   \n",
       "4  <class 'bs4.element.Tag'>    p   \n",
       "5  <class 'bs4.element.Tag'>    p   \n",
       "6  <class 'bs4.element.Tag'>    p   \n",
       "7  <class 'bs4.element.Tag'>    p   \n",
       "8  <class 'bs4.element.Tag'>    p   \n",
       "9  <class 'bs4.element.Tag'>    p   \n",
       "\n",
       "                                                                  content  \n",
       "0       [https:, [//], twitter.com/BrentScher/status/1322015793593360384]  \n",
       "1  [Fact checkers created in effort to reinforce propaganda [digestion]?]  \n",
       "2                 [The battle to prevent truth from reaching the people.]  \n",
       "3                             [The battle to maintain and push division.]  \n",
       "4                                                 [Divided you are weak.]  \n",
       "5                                         [Divided you fight each other.]  \n",
       "6                                           [Divided you pose no threat.]  \n",
       "7                                                    [System of control.]  \n",
       "8                                                  [Information warfare.]  \n",
       "9                                                                     [Q]  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type</th>\n      <th>name</th>\n      <th>content</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[https:, [//], twitter.com/BrentScher/status/1322015793593360384]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Fact checkers created in effort to reinforce propaganda [digestion]?]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[The battle to prevent truth from reaching the people.]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[The battle to maintain and push division.]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Divided you are weak.]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Divided you fight each other.]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Divided you pose no threat.]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[System of control.]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Information warfare.]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>&lt;class 'bs4.element.Tag'&gt;</td>\n      <td>p</td>\n      <td>[Q]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "Messages.dataframe(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0                                                                                                                                    https:\n",
       "1                                                                                                                                      [//]\n",
       "2      in.reuters.com/article/iran-economy-rouhani-sanctions/iran-parliament-censures-rouhani-in-sign-pragmatists-losing-sway-idINKCN1LD0DL\n",
       "3                                                                                                                                        []\n",
       "4                                                                                                                          [Hassan Rouhani]\n",
       "                                                                       ...                                                                 \n",
       "127                                                                                                                                      []\n",
       "128                                                                                                                    Nothing to See Here.\n",
       "129                                                                                                                                      []\n",
       "130                                                                                                                                       Q\n",
       "131                                                                                                                                      []\n",
       "Name: content, Length: 132, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "Messages.dataframe(3005)['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<em>//</em>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <em>//</em>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"European Union\">EU</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"Edward Snowden\">@Snowden</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"Edward Snowden\">@Snowden</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"Edward Snowden\">@Snowden</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"National Security Agency\">NSA</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <abbr title=\"Original Poster or Operation\">OP</abbr>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>,\n",
       " <br/>]"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "[i for i in messages[3005].div if isinstance(i, Tag)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://twitter.com/BrentScher/status/1322015793593360384Fact checkers created in effort to reinforce propaganda [digestion]?The battle to prevent truth from reaching the people.The battle to maintain and push division.Divided you are weak.Divided you fight each other.Divided you pose no threat.System of control.Information warfare.Q']"
      ]
     },
     "metadata": {},
     "execution_count": 148
    }
   ],
   "source": [
    "Messages.sents(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https://twitter.com/BrentScher/status/1322015793593360384Fact checkers created in effort to reinforce propaganda [digestion]?The battle to prevent truth from reaching the people.The battle to maintain and push division.Divided you are weak.Divided you fight each other.Divided you pose no threat.System of control.Information warfare.Q']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "nltk.sent_tokenize(Messages.get(10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['strong', None]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "[i.name for i in meta_lar[1].find('span', 'name').children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('span', {'class': ['num']}),\n",
       " ('span', {'class': ['time']}),\n",
       " ('span', {'class': ['name']}),\n",
       " ('span', {'class': ['source']}),\n",
       " ('span', {'class': ['copy']})]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "[(i.name, i.attrs) for i in meta_lar[0].children]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "#drop entire row if name == br?\n",
    "type(Messages.dataframe(4950))"
   ]
  },
  {
   "source": [
    "Now that we have the index taken care of, we can now focus on how to replace\n",
    "\n",
    "abbr keys with their values in the the dictionary we've been adding too\n",
    "\n",
    "Remember the are abbrs we want to skip as an exception: POTUS, FBI, HRC, abbrs\n",
    "\n",
    "whose meaning is obvious and likely won't cloud our analysis of the language "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    ".index() returns the index of the values first appearance in a list, not all of the indices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "& 182\nMSM 216\nID 246\nID 246\nSA 290\n"
     ]
    }
   ],
   "source": [
    "for item in Messages.split(4800):\n",
    "    if item in replace_dict.keys():\n",
    "        print(item, Messages.split(4800).index(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = [i for i,e in enumerate(Messages.split(4800)) if e in replace_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['&']"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "[e for i,e in enumerate(Messages.split(4800)) if i == 182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['&', 'ID', 'ID']"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "[e for i,e in enumerate(Messages.split(4800)) if i in index_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'and'"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "replace_dict.get('&')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Replace an abbr with its value in the replacement_dict: \n",
    "\n",
    "for scanner function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "How\nbad\nis\nthe\ncorruption?\nFBI\n(past/present)\n#1\n#1\n#2\n+29\n(16)\nDOJ\n(past/present)\n#1\n#1\n#2\n+18\nSTATE\n(past/present)\n#1\n#1\n+41\nRemoval\nis\nthe\nleast\nof\ntheir\nproblems.\nProjection.\nRussia>D/\nHRC\nTwitter\nBots>\nGOOG\noperated\n(not\nRussia)/Narrative\nand\nPolitical\nSLANT\nBIDEN\n/\nCHINA.\nBIG\nDEVELOPMENT.\nTRAITORS\nEVERYWHERE.\nAMERICA\nFOR\nSALE.\nFLYNN.\nTargeted.\nWhy?\nWho\nknows\nwhere\nthe\nbodies\nare\nburied?\nCLEARED\nOF\nALL\nCHARGES.\nTRUMP\nADMIN\nv2?\nElection\ntheft.\nLast\nhope.\nCongressional\nfocus.\nImpeach.\nThey\nthink\nyou\nare\nSTUPID.\nThey\nthink\nyou\nwill\nfollow\nthe\nSTARS.\nThey\nopenly\ncall\nyou\nSHEEP/CATTLE.\nTHERE\nWILL\nCOME\nA\nTIME\nNONE\nOF\nTHEM\nWILL\nBE\nABLE\nTO\nWALK\nDOWN\nTHE\nSTREET.\nBIGGEST\nFEAR.\nPUBLIC\nAWAKENING.\nQ\n"
     ]
    }
   ],
   "source": [
    "for item in Messages.split(4000):\n",
    "    if item in replace_dict.keys():\n",
    "        item =  replace_dict.get(item)\n",
    "        print(item)\n",
    "    else:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "59           EU\n",
       "89     @Snowden\n",
       "95     @Snowden\n",
       "103    @Snowden\n",
       "109         NSA\n",
       "119          OP\n",
       "Name: content, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "Messages.get_abbr(3005)['content'].explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['https: // in.reuters.com/article/iran-economy-rouhani-sanctions/iran-parliament-censures-rouhani-in-sign-pragmatists-losing-sway-idINKCN1LD0DL [Hassan Rouhani] Who paid HUSSEIN to attend HARVARD LAW SCHOOL?',\n",
       " 'Who is Prince Alwaleed bin Talal?',\n",
       " 'Why would Prince Alwaleed bin Talal (Saudi Royal) pay HUSSEIN to attend HARVARD LAW SCHOOL?',\n",
       " 'Was HUSSEIN a prominent political figure or a person of influence at the time?',\n",
       " 'No.',\n",
       " 'Who is Valerie Jarrett?',\n",
       " 'Where was she born?',\n",
       " 'When did Valerie Jarrett hire Michelle Robinson?',\n",
       " '1991 Timeline.',\n",
       " 'https: // www.thisisinsider.com/how-did-barack-and-michelle-obama-meet-2017-10#1991-they-got-engaged-in-a-simple-and-sweet-way-3 Who is Mayor (former) Richard Daley?',\n",
       " 'Who is Mayor (current) Rahm Emanuel?',\n",
       " 'HUSSEIN should be VERY nervous.',\n",
       " 'BRENNAN should be VERY nervous.',\n",
       " 'KERRY should be VERY nervous.',\n",
       " 'MERKEL should be VERY nervous.',\n",
       " '+29 How were the pallets of cash divided?',\n",
       " 'How many planes were used to transport?',\n",
       " 'Who operated the planes?',\n",
       " \"What 'shadow' agency directed operations?\",\n",
       " \"Why wasn't the money [simply] wire transferred?\",\n",
       " 'US had AUTH to open bank-to-bank transfers.',\n",
       " 'How do you prevent financial T logs?',\n",
       " 'How were the cash withdrawals in  EU  categorized/labeled?',\n",
       " 'Where did the cash originate from?',\n",
       " 'What time of day did the withdrawals occur?',\n",
       " 'Who provided SECURITY?',\n",
       " \"Why wasn't Congress notified?\",\n",
       " \"Why was the U.S. Gov't kept in the DARK?\",\n",
       " 'US law broken?',\n",
       " 'Did ALL planes land in the same location (airport)?',\n",
       " 'Why did [1] particular plane land outside of Iran?',\n",
       " 'Why was a helicopter involved?',\n",
       " '[WHO] did the money go to?',\n",
       " 'HOW DO YOU AUDIT A FOREIGN AID BIG BLOCK TRANSFER?',\n",
       " \"Did Rouhani keep 'unknown' comms as insurance?\",\n",
       " 'What agency collects ALL FORMS OF DATA?',\n",
       " 'What agency did  @Snowden  work for orig?',\n",
       " 'Did he train on THE FARM?',\n",
       " 'When did  @Snowden  join No Such Agency?',\n",
       " \"Define 'Contractor'.\",\n",
       " \"Define the 'PRISM' program.\",\n",
       " 'What year did  @Snowden  release spec-details of PRISM?',\n",
       " 'Mid 2013?',\n",
       " \"IMPACT-LIMIT  NSA 's ability to utilize/collect?\",\n",
       " 'FAKE NEWS push for Congressional restrictions?',\n",
       " 'OPEN SOURCE PUSH to create COUNTER-DEF?',\n",
       " 'PURPOSE?',\n",
       " 'BLUE SKIES FOR CLOWN  OP ?',\n",
       " 'When was the Joint Plan of Action (IRAN DEAL) executed?',\n",
       " 'Late 2013?',\n",
       " 'Do you believe in coincidences?',\n",
       " 'Nothing to See Here.',\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "Messages.sents(3005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['>>2628721Never have I been so proud to be an Army Soldier!',\n",
       " 'Hooah!',\n",
       " 'Hooah!',\n",
       " 'Soldier.',\n",
       " 'Thank you for your service.',\n",
       " 'God bless.',\n",
       " 'Q So, aha, QYou now have half the board thinking ES is Eric Schmidt and the other half think ES is Edward SnowdenPlease confirm which It should be clear in this context  ES  =  @Snowden It should be clear based on prev drop re: game comms why  ES  was included.',\n",
       " \"It should be clear that ' ES ' was used in both ( GOOG  +  @Snowden ) drops to est a link.\",\n",
       " 'Q']"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "Messages.sents(3042)"
   ]
  },
  {
   "source": [
    "this should be the new split logic; what happens otherwise is that the link will be broken up\n",
    "\n",
    "this way, we can edit it out in one pass \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['https://in.reuters.com/article/iran-economy-rouhani-sanctions/iran-parliament-censures-rouhani-in-sign-pragmatists-losing-sway-idINKCN1LD0DL',\n",
       "  '[Hassan',\n",
       "  'Rouhani]',\n",
       "  'Who',\n",
       "  'paid',\n",
       "  'HUSSEIN',\n",
       "  'to',\n",
       "  'attend',\n",
       "  'HARVARD',\n",
       "  'LAW',\n",
       "  'SCHOOL?'],\n",
       " ['Who', 'is', 'Prince', 'Alwaleed', 'bin', 'Talal?'],\n",
       " ['Why',\n",
       "  'would',\n",
       "  'Prince',\n",
       "  'Alwaleed',\n",
       "  'bin',\n",
       "  'Talal',\n",
       "  '(Saudi',\n",
       "  'Royal)',\n",
       "  'pay',\n",
       "  'HUSSEIN',\n",
       "  'to',\n",
       "  'attend',\n",
       "  'HARVARD',\n",
       "  'LAW',\n",
       "  'SCHOOL?'],\n",
       " ['Was',\n",
       "  'HUSSEIN',\n",
       "  'a',\n",
       "  'prominent',\n",
       "  'political',\n",
       "  'figure',\n",
       "  'or',\n",
       "  'a',\n",
       "  'person',\n",
       "  'of',\n",
       "  'influence',\n",
       "  'at',\n",
       "  'the',\n",
       "  'time?'],\n",
       " ['No.'],\n",
       " ['Who', 'is', 'Valerie', 'Jarrett?'],\n",
       " ['Where', 'was', 'she', 'born?'],\n",
       " ['When', 'did', 'Valerie', 'Jarrett', 'hire', 'Michelle', 'Robinson?'],\n",
       " ['1991', 'Timeline.'],\n",
       " ['https://www.thisisinsider.com/how-did-barack-and-michelle-obama-meet-2017-10#1991-they-got-engaged-in-a-simple-and-sweet-way-3',\n",
       "  'Who',\n",
       "  'is',\n",
       "  'Mayor',\n",
       "  '(former)',\n",
       "  'Richard',\n",
       "  'Daley?'],\n",
       " ['Who', 'is', 'Mayor', '(current)', 'Rahm', 'Emanuel?'],\n",
       " ['HUSSEIN', 'should', 'be', 'VERY', 'nervous.'],\n",
       " ['BRENNAN', 'should', 'be', 'VERY', 'nervous.'],\n",
       " ['KERRY', 'should', 'be', 'VERY', 'nervous.'],\n",
       " ['MERKEL', 'should', 'be', 'VERY', 'nervous.'],\n",
       " ['+29', 'How', 'were', 'the', 'pallets', 'of', 'cash', 'divided?'],\n",
       " ['How', 'many', 'planes', 'were', 'used', 'to', 'transport?'],\n",
       " ['Who', 'operated', 'the', 'planes?'],\n",
       " ['What', \"'shadow'\", 'agency', 'directed', 'operations?'],\n",
       " ['Why', \"wasn't\", 'the', 'money', '[simply]', 'wire', 'transferred?'],\n",
       " ['US', 'had', 'AUTH', 'to', 'open', 'bank-to-bank', 'transfers.'],\n",
       " ['How', 'do', 'you', 'prevent', 'financial', 'T', 'logs?'],\n",
       " ['How',\n",
       "  'were',\n",
       "  'the',\n",
       "  'cash',\n",
       "  'withdrawals',\n",
       "  'in',\n",
       "  'EU',\n",
       "  'categorized/labeled?'],\n",
       " ['Where', 'did', 'the', 'cash', 'originate', 'from?'],\n",
       " ['What', 'time', 'of', 'day', 'did', 'the', 'withdrawals', 'occur?'],\n",
       " ['Who', 'provided', 'SECURITY?'],\n",
       " ['Why', \"wasn't\", 'Congress', 'notified?'],\n",
       " ['Why', 'was', 'the', 'U.S.', \"Gov't\", 'kept', 'in', 'the', 'DARK?'],\n",
       " ['US', 'law', 'broken?'],\n",
       " ['Did',\n",
       "  'ALL',\n",
       "  'planes',\n",
       "  'land',\n",
       "  'in',\n",
       "  'the',\n",
       "  'same',\n",
       "  'location',\n",
       "  '(airport)?'],\n",
       " ['Why',\n",
       "  'did',\n",
       "  '[1]',\n",
       "  'particular',\n",
       "  'plane',\n",
       "  'land',\n",
       "  'outside',\n",
       "  'of',\n",
       "  'Iran?'],\n",
       " ['Why', 'was', 'a', 'helicopter', 'involved?'],\n",
       " ['[WHO]', 'did', 'the', 'money', 'go', 'to?'],\n",
       " ['HOW',\n",
       "  'DO',\n",
       "  'YOU',\n",
       "  'AUDIT',\n",
       "  'A',\n",
       "  'FOREIGN',\n",
       "  'AID',\n",
       "  'BIG',\n",
       "  'BLOCK',\n",
       "  'TRANSFER?'],\n",
       " ['Did', 'Rouhani', 'keep', \"'unknown'\", 'comms', 'as', 'insurance?'],\n",
       " ['What', 'agency', 'collects', 'ALL', 'FORMS', 'OF', 'DATA?'],\n",
       " ['What', 'agency', 'did', '@Snowden', 'work', 'for', 'orig?'],\n",
       " ['Did', 'he', 'train', 'on', 'THE', 'FARM?'],\n",
       " ['When', 'did', '@Snowden', 'join', 'No', 'Such', 'Agency?'],\n",
       " ['Define', \"'Contractor'.\"],\n",
       " ['Define', 'the', \"'PRISM'\", 'program.'],\n",
       " ['What',\n",
       "  'year',\n",
       "  'did',\n",
       "  '@Snowden',\n",
       "  'release',\n",
       "  'spec-details',\n",
       "  'of',\n",
       "  'PRISM?'],\n",
       " ['Mid', '2013?'],\n",
       " ['IMPACT-LIMIT', \"NSA's\", 'ability', 'to', 'utilize/collect?'],\n",
       " ['FAKE', 'NEWS', 'push', 'for', 'Congressional', 'restrictions?'],\n",
       " ['OPEN', 'SOURCE', 'PUSH', 'to', 'create', 'COUNTER-DEF?'],\n",
       " ['PURPOSE?'],\n",
       " ['BLUE', 'SKIES', 'FOR', 'CLOWN', 'OP?'],\n",
       " ['When',\n",
       "  'was',\n",
       "  'the',\n",
       "  'Joint',\n",
       "  'Plan',\n",
       "  'of',\n",
       "  'Action',\n",
       "  '(IRAN',\n",
       "  'DEAL)',\n",
       "  'executed?'],\n",
       " ['Late', '2013?'],\n",
       " ['Do', 'you', 'believe', 'in', 'coincidences?'],\n",
       " ['Nothing', 'to', 'See', 'Here.'],\n",
       " ['Q']]"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "[Messages.sents(3005)[i].split() for i in range(0, len(Messages.sents(3005)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem_strings(integer:int):\n",
    "    item = [e for i,e in enumerate([re.sub(r'https\\S+\\b', '', item) for item in Messages.split(integer)]) if not e.isalpha()]\n",
    "    item_idx = [i for i,e in enumerate([re.sub(r'https\\S+\\b', '', item) for item in Messages.split(integer)]) if not e.isalpha()]\n",
    "    return list(zip(item_idx, item))\n",
    "\n",
    "def upper_strings(integer:int):\n",
    "    item = [e for i,e in enumerate([re.sub(r'https\\S+\\b', '', item) for item in Messages.split(integer)]) if e.isupper()]\n",
    "    item_idx = [i for i,e in enumerate([re.sub(r'https\\S+\\b', '', item) for item in Messages.split(integer)]) if e.isupper()]\n",
    "    return list(zip(item_idx, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5, 'HUSSEIN'),\n",
       " (8, 'HARVARD'),\n",
       " (9, 'LAW'),\n",
       " (10, 'SCHOOL?'),\n",
       " (26, 'HUSSEIN'),\n",
       " (29, 'HARVARD'),\n",
       " (30, 'LAW'),\n",
       " (31, 'SCHOOL?'),\n",
       " (33, 'HUSSEIN'),\n",
       " (77, 'HUSSEIN'),\n",
       " (80, 'VERY'),\n",
       " (82, 'BRENNAN'),\n",
       " (85, 'VERY'),\n",
       " (87, 'KERRY'),\n",
       " (90, 'VERY'),\n",
       " (92, 'MERKEL'),\n",
       " (95, 'VERY'),\n",
       " (128, 'US'),\n",
       " (130, 'AUTH'),\n",
       " (140, 'T'),\n",
       " (148, 'EU'),\n",
       " (166, 'SECURITY?'),\n",
       " (174, 'U.S.'),\n",
       " (179, 'DARK?'),\n",
       " (180, 'US'),\n",
       " (184, 'ALL'),\n",
       " (206, '[WHO]'),\n",
       " (212, 'HOW'),\n",
       " (213, 'DO'),\n",
       " (214, 'YOU'),\n",
       " (215, 'AUDIT'),\n",
       " (216, 'A'),\n",
       " (217, 'FOREIGN'),\n",
       " (218, 'AID'),\n",
       " (219, 'BIG'),\n",
       " (220, 'BLOCK'),\n",
       " (221, 'TRANSFER?'),\n",
       " (232, 'ALL'),\n",
       " (233, 'FORMS'),\n",
       " (234, 'OF'),\n",
       " (235, 'DATA?'),\n",
       " (247, 'THE'),\n",
       " (248, 'FARM?'),\n",
       " (260, \"'PRISM'\"),\n",
       " (269, 'PRISM?'),\n",
       " (272, 'IMPACT-LIMIT'),\n",
       " (277, 'FAKE'),\n",
       " (278, 'NEWS'),\n",
       " (283, 'OPEN'),\n",
       " (284, 'SOURCE'),\n",
       " (285, 'PUSH'),\n",
       " (288, 'COUNTER-DEF?'),\n",
       " (289, 'PURPOSE?'),\n",
       " (290, 'BLUE'),\n",
       " (291, 'SKIES'),\n",
       " (292, 'FOR'),\n",
       " (293, 'CLOWN'),\n",
       " (294, 'OP?'),\n",
       " (302, '(IRAN'),\n",
       " (303, 'DEAL)'),\n",
       " (316, 'Q')]"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ],
   "source": [
    "upper_strings(3005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_string(integer: int):\n",
    "    length = len(Messages.split(integer))\n",
    "    \n",
    "    for s in Messages.split(integer):  \n",
    "        str_length = [len(s) for s in Messages.split(3005)]\n",
    "        word_idx = Messages.split(integer).index(s)\n",
    "\n",
    "        for char in s:           \n",
    "            for idx in range(0, length):\n",
    "                char_list = [char for char in Messages.split(integer)[idx] if char in string.punctuation]\n",
    "                char_idx = [i for i,e in enumerate(Messages.split(integer)[idx]) if e in string.punctuation]\n",
    "\n",
    "        return str_length"
   ]
  },
  {
   "source": [
    "index of characters in the string which are punctuation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[5,\n",
       " 6,\n",
       " 7,\n",
       " 10,\n",
       " 18,\n",
       " 22,\n",
       " 30,\n",
       " 35,\n",
       " 43,\n",
       " 51,\n",
       " 61,\n",
       " 66,\n",
       " 77,\n",
       " 86,\n",
       " 94,\n",
       " 97,\n",
       " 102,\n",
       " 114,\n",
       " 121,\n",
       " 126]"
      ]
     },
     "metadata": {},
     "execution_count": 126
    }
   ],
   "source": [
    "[i for i,e in enumerate(Messages.split(3005)[0]) if e in string.punctuation]"
   ]
  },
  {
   "source": [
    "index and characters on the first string as a tuple"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(5, ':'),\n",
       " (6, '/'),\n",
       " (7, '/'),\n",
       " (10, '.'),\n",
       " (18, '.'),\n",
       " (22, '/'),\n",
       " (30, '/'),\n",
       " (35, '-'),\n",
       " (43, '-'),\n",
       " (51, '-'),\n",
       " (61, '/'),\n",
       " (66, '-'),\n",
       " (77, '-'),\n",
       " (86, '-'),\n",
       " (94, '-'),\n",
       " (97, '-'),\n",
       " (102, '-'),\n",
       " (114, '-'),\n",
       " (121, '-'),\n",
       " (126, '-')]"
      ]
     },
     "metadata": {},
     "execution_count": 107
    }
   ],
   "source": [
    "[(i,e) for i,e in enumerate(Messages.split(3005)[0]) if e in string.punctuation]"
   ]
  },
  {
   "source": [
    "length of string"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "len(Messages.split(3005)[0])"
   ]
  },
  {
   "source": [
    "number of strings"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "len(Messages.split(3005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scanning can be implented in a function and must occur after hyperlinks have been removed\n",
    "\n",
    "# Messages.split(integer)[j] for j in range(0, len(Messages.split(integer)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}